---
title: "Assignment_3"
author: "YASHWANTH REDDY SADALA"
date: "10-15-2023"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

``````{r setup, include=TRUE,  results='hide'}
knitr::opts_chunk$set(echo = TRUE)
```

#Summary
1. Using the information in this dataset, if an accident has just been reported and no further information is available, what should the prediction be? (INJURY = Yes or No?) Why?
Ans: According to the data in this dataset, there is a 50.88% chance that an injury occurred if an accident has just been reported and no other information is available. This is because data indicates that earlier out of 42,183 cases, 21,462 cases had reported "injury=yes."

2. Select the first 24 records in the dataset and look only at the response (INJURY) and the two predictors WEATHER_R and TRAF_CON_R. Create a pivot table that examines INJURY as a function of the two predictors for these 12 records. Use all three variables in the pivot table as rows/columns?
2.1:- Compute the exact Bayes conditional probabilities of an injury (INJURY = Yes) given the six possible combinations of the predictors?
Ans: For each of the six potential combinations of the predictors, the precise Bayes conditional probabilities of an injury (INJURY = Yes) are:

Predictor combination	Probability
WEATHER_R = 1 and TRAF_CON_R = 1	0.6666667
WEATHER_R = 2 and TRAF_CON_R = 0	0.1818182
WEATHER_R = 1 and TRAF_CON_R = 1	0.0000000
WEATHER_R = 2 and TRAF_CON_R = 1	0.0000000
WEATHER_R = 1 and TRAF_CON_R = 2	0.0000000
WEATHER_R = 2 and TRAF_CON_R = 2	1.0000000

2.2:-Classify the 24 accidents using these probabilities and a cutoff of 0.5?
Ans: The 24 accidents are quantitatively classified using their probability and a cutoff of 0.5:

[0.6666667 0.1818182 0.0000000 0.0000000 0.6666667 0.1818182 0.1818182 0.6666667 0.1818182 0.1818182 0.1818182 0.0000000 0.6666667 0.6666667 0.6666667 0.6666667 0.1818182 0.1818182 0.1818182 0.1818182 0.6666667 0.6666667 1.0000000 0.1818182]

qualitatively are:

["yes" "no" "no" "no" "yes" "no" "no" "yes" "no" "no" "no" "no" "yes" "yes" "yes" "yes" "no" "no" "no" "no" "yes" "yes" "yes" "no"]

2.3:-Compute manually the naive Bayes conditional probability of an injury given WEATHER_R = 1 and TRAF_CON_R = 1?
Ans: The probability or output was "0" when the naive Bayes conditional probability of an injury was manually calculated using WEATHER_R = 1 and TRAF_CON_R = 1.

2.4:-Run a naive Bayes classifier on the 24 records and two predictors. Check the model output to obtain probabilities and classifications for all 24 records. Compare this to the exact Bayes classification. Are the resulting classifications equivalent? Is the ranking (= ordering) of observations equivalent?
Ans: Now that the naive Bayes classifier has been applied to the 24 records and two predictors, it has been discovered that the resultant classifications and rankings do not match those of the exact Bayes computation. This was discovered after checking the model output to acquire probabilities and classifications for all 24 records.

3. Let us now return to the entire dataset. Partition the data into training (60%) and validation (40%)?
3.1:- Run a naive Bayes classifier on the complete training set with the relevant predictors (and INJURY as the response). Note that all predictors are categorical. Show the confusion matrix?
Ans: Using the naive Bayes classifier on the complete training set with the relevant predictors (and INJURY as the response) The Following Confusion Matrix and Statistics are obtained. The accuracy comes out to be 53.7%.

Confusion Matrix and Statistics

          Reference
Prediction   no  yes
       no  3444 4866
       yes 2947 5617
                                          
               Accuracy : 0.537  

3.2:- What is the overall error of the validation set?
Ans: The overall error of the validation set is "46.3".



# Problem Statement

The file accidentsFull.csv contains information on 42,183 actual automobile accidents in 2001 in the United States that involved one of three levels of injury: NO INJURY, INJURY, or FATALITY. For each accident, additional information is recorded, such as day of week, weather conditions, and road type. A firm might be interested in developing a system for quickly classifying the severity of an accident based on initial reports and associated data in the system (some of which rely on GPS-assisted reporting).

Our goal here is to predict whether an accident just reported will involve an injury (MAX_SEV_IR = 1 or 2) or will not (MAX_SEV_IR = 0). For this purpose, create a dummy variable called INJURY that takes the value “yes” if MAX_SEV_IR = 1 or 2, and otherwise “no.”

1. Using the information in this dataset, if an accident has just been reported and no further information is available, what should the prediction be? (INJURY = Yes or No?) Why?
2. Select the first 24 records in the dataset and look only at the response (INJURY) and the two predictors WEATHER_R and TRAF_CON_R. Create a pivot table that examines INJURY as a function of the two predictors for these 12 records. Use all three variables in the pivot table as rows/columns.
  2.1:- Compute the exact Bayes conditional probabilities of an injury (INJURY = Yes) given the six possible combinations of the predictors.
  2.2:-Classify the 24 accidents using these probabilities and a cutoff of 0.5.
  2.3:-Compute manually the naive Bayes conditional probability of an injury given WEATHER_R = 1 and TRAF_CON_R = 1.
  2.4:-Run a naive Bayes classifier on the 24 records and two predictors. Check the model output to obtain probabilities and classifications for all 24 records. Compare this to the exact Bayes classification. Are the resulting classifications equivalent? Is the ranking (= ordering) of observations equivalent?
3. Let us now return to the entire dataset. Partition the data into training (60%) and validation (40%). 
  3.1:- Run a naive Bayes classifier on the complete training set with the relevant predictors (and INJURY as the response). Note that all predictors are categorical. Show the confusion matrix.
  3.2:- What is the overall error of the validation set?
  
## Data Importing and Cleaning
Install and load the required  package
```{r}
library(e1071)
library(caret)
library(ggplot2)
```

Q1. Using the information in this dataset, if an accident has just been reported and no further information is available, what should the prediction be? (INJURY = Yes or No?) Why?
```{r}
accidents <- read.csv("C:\\Users\\yashw\\FML\\accidentsFull.csv")
accidents$INJURY = ifelse(accidents$MAX_SEV_IR>0,"yes","no")
injury_table <- table(accidents$INJURY)
injury_table
head(accidents)
probability_injury <- (injury_table["yes"] / sum(injury_table))*100
probability_injury

```

```{r}
#converting factors from variables
for (i in c(1:dim(accidents)[2])){
  accidents[,i] <- as.factor(accidents[,i])
}
head(accidents,n=24)
```

Q2. Select the first 24 records in the dataset and look only at the response (INJURY) and the two predictors WEATHER_R and TRAF_CON_R. Create a pivot table that examines INJURY as a function of the two predictors for these 12 records. Use all three variables in the pivot table as rows/columns.
  2.1:- Compute the exact Bayes conditional probabilities of an injury (INJURY = Yes) given the six possible combinations of the predictors.
  2.2:-Classify the 24 accidents using these probabilities and a cutoff of 0.5.
  2.3:=Compute manually the naive Bayes conditional probability of an injury given WEATHER_R = 1 and TRAF_CON_R = 1.
  2.4:-Run a naive Bayes classifier on the 24 records and two predictors. Check the model output to obtain probabilities and classifications for all 24 records. Compare this to the exact Bayes classification. Are the resulting classifications equivalent? Is the ranking (= ordering) of observations equivalent?

```{r}
accidents24 <- accidents[1:24,c("INJURY","WEATHER_R","TRAF_CON_R")]
head(accidents24)
```

```{r}
Pt1 <- ftable(accidents24)
Pt2 <- ftable(accidents24[,-1]) # print table only for conditions
Pt1
Pt2
```

2.1:- Compute the exact Bayes conditional probabilities of an injury (INJURY = Yes) given the six possible combinations of the predictors.
```{r}
#Injury = yes
p1 = Pt1[3,1] / Pt2[1,1] # Injury, Weather=1 and Traf=0
p2 = Pt1[4,1] / Pt2[2,1] # Injury, Weather=2, Traf=0
p3 = Pt1[3,2] / Pt2[1,2] # Injury, W=1, T=1
p4 = Pt1[4,2] / Pt2[2,2] # I, W=2,T=1
p5 = Pt1[3,3] / Pt2[1,3] # I, W=1,T=2
p6 = Pt1[4,3]/ Pt2[2,3] #I,W=2,T=2

# Injury = no
n1 = Pt1[1,1] / Pt2[1,1] # Weather=1 and Traf=0
n2 = Pt1[2,1] / Pt2[2,1] # Weather=2, Traf=0
n3 = Pt1[1,2] / Pt2[1,2] # W=1, T=1
n4 = Pt1[2,2] / Pt2[2,2] # W=2,T=1
n5 = Pt1[1,3] / Pt2[1,3] # W=1,T=2
n6 = Pt1[2,3] / Pt2[2,3] # W=2,T=2
print(c(p1,p2,p3,p4,p5,p6))
print(c(n1,n2,n3,n4,n5,n6))
```

2.2:-Classify the 24 accidents using these probabilities and a cutoff of 0.5.
```{r}
prob.inj <- rep(0,24)

for (i in 1:24) {
  print(c(accidents24$WEATHER_R[i],accidents24$TRAF_CON_R[i]))
    if (accidents24$WEATHER_R[i] == "1") {
      if (accidents24$TRAF_CON_R[i]=="0"){
        prob.inj[i] = p1
      }
      else if (accidents24$TRAF_CON_R[i]=="1") {
        prob.inj[i] = p3
      }
      else if (accidents24$TRAF_CON_R[i]=="2") {
        prob.inj[i] = p5
      }
    }
    else {
      if (accidents24$TRAF_CON_R[i]=="0"){
        prob.inj[i] = p2
      }
      else if (accidents24$TRAF_CON_R[i]=="1") {
        prob.inj[i] = p4
      }
      else if (accidents24$TRAF_CON_R[i]=="2") {
        prob.inj[i] = p6
      }
    }
  }
  

accidents24$prob.inj <- prob.inj
accidents24$prob.inj
accidents24$pred.prob <- ifelse(accidents24$prob.inj>0.5, "yes", "no")
accidents24$pred.prob

```

2.3Compute manually the naive Bayes conditional probability of an injury given WEATHER_R = 1 and TRAF_CON_R = 1.
Answer:- Probability(Injury=Yes/WEATHER_R=1,TRAF_CON_R=1)

= [ Probability(W=1/Injury=Yes) * Probability(TRAF_CON_R=1/Injury=Yes) * Probability(Injury=Yes) ]
                                                /
[ Probability(W=1/Injury=Yes) * Probability(TRAF_CON_R=1/Injury=Yes) * Probability(Injury=Yes) + Probability(WEATHER_R=1/Injury=No) * Probability(TRAF_CON_R=1/Injury=No) * Probability(Injury=No) ]

= [ 6/9 * 0/9 * 9/24 ] / [ 6/9 * 0/9 * 9/24 + 5/15 * 2/15 * 15/24 ] 
=  The result will be "0" since the numerator is equal to zero.


2.4:- Run a naive Bayes classifier on the 24 records and two predictors. Check the model output to obtain probabilities and classifications for all 24 records. Compare this to the exact Bayes classification. Are the resulting classifications equivalent? Is the ranking (= ordering) of observations equivalent?
```{r}
nb <- naiveBayes(INJURY ~ TRAF_CON_R + WEATHER_R, 
                 data = accidents24)

nbt <- predict(nb, newdata = accidents24,type = "raw")
accidents24$nbpred.prob <- nbt[,2] # Transfer the "Yes" nb prediction
accidents24$nbpred.prob
```
  
Let us use Caret
```{r}

library(klaR) 
#Loading the klaR package for Naive Bayes

# Creating a variable named formula that includes all variables of interest
formula <- INJURY ~ TRAF_CON_R + WEATHER_R
# Training the Naive Bayes model with Laplace

accidents24$INJURY <- as.factor(accidents24$INJURY)
nb2 <- NaiveBayes(formula,data = accidents24, laplace = 1)

# Making predictions with the model
 predict(nb2, newdata = accidents24[, c("INJURY", "WEATHER_R", "TRAF_CON_R")])

predict(nb2, newdata = accidents24[, c("INJURY", "WEATHER_R", "TRAF_CON_R")], type = "raw")
#predictions
#raw_probabilities

```

```{r}
# Comparing the naive Bayes model and exact Bayes classification
classification_match <- all(accidents24$nbpred.prob == accidents24$prob.inj)
probability_match <- all.equal(accidents24$nbpred.prob, accidents24$prob.inj)

# Checking if classifications and rankings are equivalent
if (classification_match && is.na(probability_match)) {
  cat("The resulting classifications and rankings are equivalent.\n")
} else {
  cat("The resulting classifications and rankings are not equivalent.\n")
}

```

Q3, Let us now return to the entire dataset. Partition the data into training (60%) and validation (40%). 
3.1, Run a naive Bayes classifier on the complete training set with the relevant predictors(and INJURY as the response). Note that all predictors are categorical. Show the confusion matrix.

```{r}
set.seed(123)
train.index <- sample(c(1:dim(accidents)[1]), dim(accidents)[1]*0.6)  
train.df <- accidents[train.index,]
valid.df <- accidents[-train.index,]
#defining a variable to be used here
vars <- c("INJURY", "HOUR_I_R",  "ALIGN_I" ,"WRK_ZONE",  "WKDY_I_R",
          "INT_HWY",  "LGTCON_I_R", "PROFIL_I_R", "SPD_LIM", "SUR_COND",
          "TRAF_CON_R",   "TRAF_WAY",   "WEATHER_R")

nbTotal <- naiveBayes(INJURY~.,data = train.df[,vars])
nbTotal

#generating the confusion matrix using the train.df, the prediction and the classes
confusionMatrix(train.df$INJURY, predict(nbTotal, train.df[, vars]), positive = "yes")
```

3.2, What is the overall error of the validation set?
```{r}
confusionMatrix(valid.df$INJURY, predict(nbTotal, valid.df[, vars]), positive = "yes")
```

```{r}
#Calculated overall error

ver=1-0.537
verp=ver*100
paste("Overall Error: ",verp)
```

#CONCLUSION 

The Naive Bayes classifier was used firstly to predict injury outcomes in a data set with 24 records then to the entire data set with using two predictors both times.

Using the exact Bayes classifier for the first 24 records, we discover that the most risky combination for drivers is WEATHER_CON=2,TRAF_CON=0 because the likelihood for injury is maximal at "1" in this case.

The model's accuracy on the training set was 53.7%, and its validation error was 46.3%, showing a modest level of predictive ability. However, it makes the assumption that the predictor variables are independent, which may not always be the case in real-world situations and might result in errors.But for classification and ranking, we can utilize the Naive Bayes classifier.
Although Naive Bayes is a straightforward and useful